{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load the data from “college.csv” that has attributes collected about private and public colleges for a particular year. We will try to predict the private/public status of the college from other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Private  Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0     Yes  1660    1232     721         23         52         2885   \n",
       "1     Yes  2186    1924     512         16         29         2683   \n",
       "2     Yes  1428    1097     336         22         50         1036   \n",
       "3     Yes   417     349     137         60         89          510   \n",
       "4     Yes   193     146      55         16         44          249   \n",
       "\n",
       "   P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "\n",
       "   S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('c:/edureka/college.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private        0\n",
       "Apps           0\n",
       "Accept         0\n",
       "Enroll         0\n",
       "Top10perc      0\n",
       "Top25perc      0\n",
       "F.Undergrad    0\n",
       "P.Undergrad    0\n",
       "Outstate       0\n",
       "Room.Board     0\n",
       "Books          0\n",
       "Personal       0\n",
       "PhD            0\n",
       "Terminal       0\n",
       "S.F.Ratio      0\n",
       "perc.alumni    0\n",
       "Expend         0\n",
       "Grad.Rate      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 18 columns):\n",
      "Private        777 non-null object\n",
      "Apps           777 non-null int64\n",
      "Accept         777 non-null int64\n",
      "Enroll         777 non-null int64\n",
      "Top10perc      777 non-null int64\n",
      "Top25perc      777 non-null int64\n",
      "F.Undergrad    777 non-null int64\n",
      "P.Undergrad    777 non-null int64\n",
      "Outstate       777 non-null int64\n",
      "Room.Board     777 non-null int64\n",
      "Books          777 non-null int64\n",
      "Personal       777 non-null int64\n",
      "PhD            777 non-null int64\n",
      "Terminal       777 non-null int64\n",
      "S.F.Ratio      777 non-null float64\n",
      "perc.alumni    777 non-null int64\n",
      "Expend         777 non-null int64\n",
      "Grad.Rate      777 non-null int64\n",
      "dtypes: float64(1), int64(16), object(1)\n",
      "memory usage: 109.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.countplot(x='Private',data=df)\n",
    "plt.figure(figsize=(5,6))\n",
    "total=df['Private'].value_counts()\n",
    "ax = sns.countplot(data=df,x='Private',ax=total.plot.bar() )\n",
    "ax.set_xticklabels([\"Private\",\"Public\"])\n",
    "for i, v in total.reset_index().iterrows():\n",
    "   ax.text(i, v.Private, v.Private)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Use LabelEncoder to encode the target variable in to numerical form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Private  Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0        1  1660    1232     721         23         52         2885   \n",
       "1        1  2186    1924     512         16         29         2683   \n",
       "2        1  1428    1097     336         22         50         1036   \n",
       "3        1   417     349     137         60         89          510   \n",
       "4        1   193     146      55         16         44          249   \n",
       "\n",
       "   P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "\n",
       "   S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencode=LabelEncoder()\n",
    "df['Private']=labelencode.fit_transform(df['Private'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 18 columns):\n",
      "Private        777 non-null int32\n",
      "Apps           777 non-null int64\n",
      "Accept         777 non-null int64\n",
      "Enroll         777 non-null int64\n",
      "Top10perc      777 non-null int64\n",
      "Top25perc      777 non-null int64\n",
      "F.Undergrad    777 non-null int64\n",
      "P.Undergrad    777 non-null int64\n",
      "Outstate       777 non-null int64\n",
      "Room.Board     777 non-null int64\n",
      "Books          777 non-null int64\n",
      "Personal       777 non-null int64\n",
      "PhD            777 non-null int64\n",
      "Terminal       777 non-null int64\n",
      "S.F.Ratio      777 non-null float64\n",
      "perc.alumni    777 non-null int64\n",
      "Expend         777 non-null int64\n",
      "Grad.Rate      777 non-null int64\n",
      "dtypes: float64(1), int32(1), int64(16)\n",
      "memory usage: 106.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['Private'],axis=1)\n",
    "y=df['Private']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the data such that 20% of the data is set aside for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Fit a linear svm from scikit learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svmodel=SVC(kernel='linear')\n",
    "svmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# observe the accuracy usin Linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18  21]\n",
      " [  1 116]]\n",
      "0.8589743589743589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Preprocess the data using StandardScalar and fit the same model again and observe the change in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled=scalar.fit_transform(X_train)\n",
    "X_test_scaled=scalar.fit_transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svmodel=SVC(kernel='linear')\n",
    "svmodel.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svmodel.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change in accuracy after StandardScalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38   1]\n",
      " [  5 112]]\n",
      "0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Use scikit learn’s gridsearch to select the best hyperparameter for a non-linear SVM, identify the model with best score and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_candidates = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(SVC(),parameter_candidates,refit=True,verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] ..... C=1, kernel=linear, score=0.9278846153846154, total=   0.0s\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] ..... C=1, kernel=linear, score=0.9468599033816425, total=   0.0s\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] ..... C=1, kernel=linear, score=0.9320388349514563, total=   0.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] .... C=10, kernel=linear, score=0.9326923076923077, total=   0.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] .... C=10, kernel=linear, score=0.9516908212560387, total=   0.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] .... C=10, kernel=linear, score=0.9320388349514563, total=   0.0s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ... C=100, kernel=linear, score=0.9326923076923077, total=   0.0s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ... C=100, kernel=linear, score=0.9468599033816425, total=   0.1s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ... C=100, kernel=linear, score=0.9320388349514563, total=   0.1s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] .. C=1000, kernel=linear, score=0.9326923076923077, total=   0.3s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] .. C=1000, kernel=linear, score=0.9468599033816425, total=   0.7s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] .. C=1000, kernel=linear, score=0.9320388349514563, total=   1.4s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.8461538461538461, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.8888888888888888, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.8640776699029126, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.7211538461538461, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.7198067632850241, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.7233009708737864, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.9230769230769231, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.9323671497584541, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.9368932038834952, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.8461538461538461, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.8888888888888888, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.8640776699029126, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.9278846153846154, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.9468599033816425, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.9368932038834952, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9182692307692307, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9323671497584541, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9320388349514563, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .... C=1000, gamma=0.001, kernel=rbf, score=0.9375, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.9468599033816425, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.941747572815534, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9278846153846154, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9420289855072463, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.941747572815534, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']}, {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select the best hyperparameter for a non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_prediction=grid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9551282051282052\n",
      "[[ 37   2]\n",
      " [  5 112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91        39\n",
      "           1       0.98      0.96      0.97       117\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       156\n",
      "   macro avg       0.93      0.95      0.94       156\n",
      "weighted avg       0.96      0.96      0.96       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(accuracy_score(y_test,grid_prediction))\n",
    "print(confusion_matrix(y_test,grid_prediction))\n",
    "print(classification_report(y_test,grid_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
